items:

- id: ricardo-ferreira
  name: Ricardo Ferreira
  bio: |
    Ricardo is Observability Lead for Elastic’s community team, where he acts as the voice of Elastic at SRE, DevOps, and DataOps communities. In this role, he is responsible for developing and driving a global community and developer advocacy strategy focused on observability. With +20 years of experience, he might have learned a thing or two about distributed systems, observability, streaming systems, and databases. Before Elastic, he worked for other vendors such as Confluent, Oracle, Red Hat, and different consulting firms.

    While not working, he loves barbecuing in his backyard with his family and friends, where he gets the chance to talk about anything that is not IT-related. He lives in North Carolina, USA, with his wife and son.
  role: presenter
  title: Building Software Reliability with Distributed Tracing
  abstract: |
    Most developers believe that building reliable software involves writing good code, implementing enough testing, and using as many proven architecture patterns as possible. The assumption is that building things this way equals creating a flawless system. Sadly, in the software world, this is not true. Software reliability is not the same as software correctness. You may write good code, implement enough testing, and use as many proven architecture patterns as possible to end up with software deemed correct. But, the code may still blow up straight on the customer’s face.

    Building software reliability is something else entirely. It requires developers to look at the code, not from the perspective of what it is supposed to do but what the code is effectively doing, with little room for guessing. Distributed tracing is a technique that developers can use to accomplish this.

    This talk will discuss how distributed tracing can positively change how you and your team deliver customers’ software. After all, five-nines of availability don’t matter if users aren’t happy. It will highlight which techniques with distributed tracing bring value, what to focus on and what avoid, and the most common challenges. By the end, you will know everything you need to adopt distributed tracing as a practice that promotes software reliability.
  handles:
    twitter: riferrei
    linkedin: riferrei

- id: michael-haberman
  name: Michael Haberman
  bio: |
    Michael is the Co-Founder and CTO of Aspecto. After serving as a software developer in an elite unit in the Israeli Intelligence branch, Michael worked with a few startups on building and scaling their microservices infrastructure. Prior to co-founding Aspecto, he was the Chief Architect at Playbuzz. In his free time, Michael also lectures and conducts workshops on microservices at conferences.
  role: presenter
  title: Trace-Based Testing with OpenTelemetry
  abstract: |
    Distributed tracing allows devs to find and fix issues in production after they happen. There is another use case for tracing data: trace-based testing. We can improve assertion capabilities by leveraging OpenTelemetry trace data and making it accessible while setting our expectations from a test.

    Companies these days use distributed tracing for critical functions such as performance monitoring and troubleshooting, allowing DevOps, developers, and SREs to find and fix issues in production after they happen. But here is the thing, they don’t use tracing to its full potential.

    There is another use case for tracing data, and that is trace-based testing. This new method allows you to improve assertion capabilities by leveraging traces data and making it accessible while setting your expectations from a test.

    We will introduce you to a new open-source called Malabi - a Javascript framework based on OpenTelemetry that allows you to easily use trace data to take your assertion capabilities to the next level.

    By the end of this session, you will know how to use trace-based testing to increase your tests’ reliability and possibly prevent issues early in the development cycle.
  handles:
    twitter: hab_mic
    linkedin: michael-haberman

- id: colin-douch
  name: Colin Douch
  bio: |
    Colin Douch is an SRE at Cloudflare, tech leading their Observability Platform, with over 10 years experience working across DevOps and SRE organisations. Originally from New Zealand, but currently living in Australia (and trying to blend in), he has worked with organisations both big and small to improve their Observability systems.
  role: presenter
  title: High Cardinality Alerting With Open Telemetry
  abstract: |
    A common problem with our existing alerting systems is that they are limited by the cardinality issues inherent in Time Series Databases. This allows them to provide a very quick signal of when something is wrong, but causes them to fail to provide enough context as to exactly what that is. The result is that the first steps of debugging an alert are generally blindly searching through higher cardinality data sources such structured logs and traces to further debug the issue. But what if it didn’t have to be that way? At Cloudflare, as part of our transition towards a tracing first Observability system, we have developed a system - “Cleodora” - that allows aggregating time series data, in memory, or persistently in Clickhouse from OpenTelemetry traces. Cleodora then allows us to create alerting rules over these aggregates, directly into our existing Alertmanager setup. This allows us to utilise the full context of each traces high dimensionality and high cardinality labels for alerting purposes, providing deeper context on alerts and allowing our engineering teams to more quickly identify and fix the root cause of incidents.

    In this talk, Colin will explain what led to Cleodoras development, where it fits into Cloudflares monitoring stack, and the benefits that it has provided; reducing the load on our Prometheus servers and providing a stepping stone to tracing introduction, allowing us to further our distributed tracing offerings. He will further discuss where Cleodora is going from here, and how other organisations can use it to start their own transitions towards a proper Observability system.
  handles:
    twitter: sinkingpoint
    linkedin: colin-douch-82940b120

- id: henrik-rexed
  name: Henrik Rexed
  bio: |
    Henrik is a Cloud Native Advocate at Dynatrace, the leading Observability platform. Prior to Dynatrace, Henrik has  worked as a Partner Solution Evangelist at Neotys, delivering webinars, building protypes to enhance the capability of NeoLoad.  He has been working in the performance world more than 15 years, delivering projects in all contexts including extremely large Cloud testing on the most demanding business areas such as trading applications, Video on Demand, sports websites, etc.

    Henrik Rexed is also one of the Organizer of the Conference named Performance Advisory Council , one of the producers of PerfBytes and the owner of the Youtube Channel IsitObservable.
  role: presenter
  title: "The Sound of Code: Instrument with OpenTelemetry"
  abstract: |
    To be efficient in our Continuous testing, continuous deployment approach and on the way we handle production outage, we need to have the right level of observability to understand properly how:

    Our users are interacting with our application
    Our system behaves with significant traffic
    Our infrastructure has been utilize by our application
    …etc
    To help us in our journey, OpenTelemetry has provided a standard on the way we are able to produce and collect measurements in our environments.

    Like any other technology transformation, OpenTelemetry adoption typically starts with small “pet projects” where we usually try to utilize manual or automatic instrumentation. But Opentelemetry is not only about producing traces, it covers the ability to generate metrics and logs from our applications. But like any new emerging framework we tend to wait to get a stable implementation before utilizing it in our production environment.

    We all understand the value of having traces generated out of our application, but the journey could seem difficult and time consuming.

    How can we utilize properly the instruments of Opentelemtry to make our code sound beautiful?

    During this presentation we will explain:
    - The various components of OpenTelemetry
    - The various core Objects required to instrument your code
    - Best practices related to instrumentation
    - The latest news related to OpenTelemetry

  handles:
    twitter: hrexed
    linkedin: hrexed
