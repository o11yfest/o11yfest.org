items:

- id: ricardo-ferreira
  name: Ricardo Ferreira
  bio: |
    Ricardo is Senior Developer Advocate at AWS, working in the developer relations team for North America. With +20 years of experience, he may have learned a thing or two about distributed systems, fast data analytics, software architecture, databases, and observability. Before joining AWS, he worked for software vendors like Elastic, Confluent, and Oracle. Ricardo is known for his natural ability to explain complex topics. He craftily breaks them down into bite-sized pieces until anyone can understand.

    While not working, he loves barbecuing in his backyard with his family and friends, where he finally gets the chance to talk about anything unrelated to computers. He currently lives in North Carolina, USA, with his wife and son. Follow Ricardo on Twitter: [@riferrei](https://twitter.com/riferrei).
  role: presenter
  title: Building Software Reliability with Distributed Tracing
  abstract: |
    Most developers believe that building reliable software involves writing good code, implementing enough testing, and using as many proven architecture patterns as possible. The assumption is that building things this way equals creating a flawless system. Sadly, in the software world, this is not true. Software reliability is not the same as software correctness. You may write good code, implement enough testing, and use as many proven architecture patterns as possible to end up with software deemed correct. But, the code may still blow up straight on the customer’s face.

    Building software reliability is something else entirely. It requires developers to look at the code, not from the perspective of what it is supposed to do but what the code is effectively doing, with little room for guessing. Distributed tracing is a technique that developers can use to accomplish this.

    This talk will discuss how distributed tracing can positively change how you and your team deliver customers’ software. After all, five-nines of availability don’t matter if users aren’t happy. It will highlight which techniques with distributed tracing bring value, what to focus on and what avoid, and the most common challenges. By the end, you will know everything you need to adopt distributed tracing as a practice that promotes software reliability.
  handles:
    twitter: riferrei
    linkedin: riferrei
  session_url: https://vi.to/hubs/o11yfest/videos/4896
  preactions:
  - contributor: Leticia Mendonca
    youtube_id: z58Sv0QaHvo
    video_url: https://www.youtube.com/watch?v=z58Sv0QaHvo

- id: michael-haberman
  name: Michael Haberman
  bio: |
    Michael is the Co-Founder and CTO of Aspecto. After serving as a software developer in an elite unit in the Israeli Intelligence branch, Michael worked with a few startups on building and scaling their microservices infrastructure. Prior to co-founding Aspecto, he was the Chief Architect at Playbuzz. In his free time, Michael also lectures and conducts workshops on microservices at conferences.
  role: presenter
  title: Trace-Based Testing with OpenTelemetry
  abstract: |
    Distributed tracing allows devs to find and fix issues in production after they happen. There is another use case for tracing data: trace-based testing. We can improve assertion capabilities by leveraging OpenTelemetry trace data and making it accessible while setting our expectations from a test.

    Companies these days use distributed tracing for critical functions such as performance monitoring and troubleshooting, allowing DevOps, developers, and SREs to find and fix issues in production after they happen. But here is the thing, they don’t use tracing to its full potential.

    There is another use case for tracing data, and that is trace-based testing. This new method allows you to improve assertion capabilities by leveraging traces data and making it accessible while setting your expectations from a test.

    We will introduce you to a new open-source called Malabi - a Javascript framework based on OpenTelemetry that allows you to easily use trace data to take your assertion capabilities to the next level.

    By the end of this session, you will know how to use trace-based testing to increase your tests’ reliability and possibly prevent issues early in the development cycle.
  handles:
    twitter: hab_mic
    linkedin: michael-haberman
  session_url: https://vi.to/hubs/o11yfest/videos/4895
  preactions:
  - contributor: Lewis Prescott
    youtube_id: hL9sHmBPleU
    video_url: https://www.youtube.com/watch?v=hL9sHmBPleU

- id: jessica-kerr
  name: Jessica (Jessitron) Kerr
  bio: |
    Jessica Kerr is a developer advocate, software developer and symmathecist with 20+ years of experience. She has worked in enterprises and startups, in Java, Scala, Clojure, Ruby, and TypeScript. Talk to her about technical details, or about how to get software to teach us about its needs.
  role: presenter
  title: Observability During Development
  abstract: |
    How will our development flow be different once we take observability for granted? Jess demonstrates what coding is like when observability is a natural part of the flow. Get insight into what the code is doing immediately, and keep that insight in production. Is 'create span' the new 'printf'?
  handles:
    twitter: jessitron
    linkedin: jessicakerr
  session_url: https://vi.to/hubs/o11yfest/videos/5086

- id: colin-douch
  name: Colin Douch
  bio: |
    Colin Douch is an SRE at Cloudflare, tech leading their Observability Platform, with over 10 years experience working across DevOps and SRE organisations. Originally from New Zealand, but currently living in Australia (and trying to blend in), he has worked with organisations both big and small to improve their Observability systems.
  role: presenter
  title: High Cardinality Alerting With Open Telemetry
  abstract: |
    A common problem with our existing alerting systems is that they are limited by the cardinality issues inherent in Time Series Databases. This allows them to provide a very quick signal of when something is wrong, but causes them to fail to provide enough context as to exactly what that is. The result is that the first steps of debugging an alert are generally blindly searching through higher cardinality data sources such structured logs and traces to further debug the issue. But what if it didn’t have to be that way? At Cloudflare, as part of our transition towards a tracing first Observability system, we have developed a system - “Cleodora” - that allows aggregating time series data, in memory, or persistently in Clickhouse from OpenTelemetry traces. Cleodora then allows us to create alerting rules over these aggregates, directly into our existing Alertmanager setup. This allows us to utilise the full context of each traces high dimensionality and high cardinality labels for alerting purposes, providing deeper context on alerts and allowing our engineering teams to more quickly identify and fix the root cause of incidents.

    In this talk, Colin will explain what led to Cleodoras development, where it fits into Cloudflares monitoring stack, and the benefits that it has provided; reducing the load on our Prometheus servers and providing a stepping stone to tracing introduction, allowing us to further our distributed tracing offerings. He will further discuss where Cleodora is going from here, and how other organisations can use it to start their own transitions towards a proper Observability system.
  handles:
    twitter: sinkingpoint
    linkedin: colin-douch-82940b120
  session_url: https://vi.to/hubs/o11yfest/videos/5026

- id: michael-hausenblas
  name: Michael Hausenblas
  bio: |
    Michael is a Solution Engineering Lead in the AWS open source observability service team. He covers Prometheus, Grafana, and OpenTelemetry upstream and in managed services. Before Amazon, Michael worked at Red Hat, Mesosphere (now D2iQ), MapR (now part of HPE), and prior to that ten years in applied research.
  role: presenter
  title: Return on Investment driven observability
  abstract: |
    No one wants to fly blind when developing & operating cloud native apps. But how do you select the signals (logs, metrics, traces, profiles) to use for a task and how can you assess how much bang you get for the buck (instrumentation, agents, destinations)? In this talk we aim to provide answers.

    In the context of developing and operating cloud native apps, such as Kubernetes workloads or AWS Lambda-based app, no one wants to fly blind. But how do you select the signals (logs, metrics, traces, profiles) to use for a certain task such as troubleshooting or performance optimization? Also, how can you assess how much bang you get for the buck (in terms of costs of instrumentation, for agents, and destinations including long-term storage)? In this talk we aim to provide answers to these questions, suggesting a “Return on Investment”- driven observability approach.
  handles:
    twitter: mhausenblas
    linkedin: mhausenblas
  session_url: https://vi.to/hubs/o11yfest/videos/5027

- id: henrik-rexed
  name: Henrik Rexed
  bio: |
    Henrik is a Cloud Native Advocate at Dynatrace, the leading Observability platform. Prior to Dynatrace, Henrik has  worked as a Partner Solution Evangelist at Neotys, delivering webinars, building protypes to enhance the capability of NeoLoad.  He has been working in the performance world more than 15 years, delivering projects in all contexts including extremely large Cloud testing on the most demanding business areas such as trading applications, Video on Demand, sports websites, etc.

    Henrik Rexed is also one of the Organizer of the Conference named Performance Advisory Council , one of the producers of PerfBytes and the owner of the Youtube Channel IsitObservable.
  role: presenter
  title: "The Sound of Code: Instrument with OpenTelemetry"
  abstract: |
    To be efficient in our Continuous testing, continuous deployment approach and on the way we handle production outage, we need to have the right level of observability to understand properly how:

    Our users are interacting with our application
    Our system behaves with significant traffic
    Our infrastructure has been utilize by our application
    …etc
    To help us in our journey, OpenTelemetry has provided a standard on the way we are able to produce and collect measurements in our environments.

    Like any other technology transformation, OpenTelemetry adoption typically starts with small “pet projects” where we usually try to utilize manual or automatic instrumentation. But Opentelemetry is not only about producing traces, it covers the ability to generate metrics and logs from our applications. But like any new emerging framework we tend to wait to get a stable implementation before utilizing it in our production environment.

    We all understand the value of having traces generated out of our application, but the journey could seem difficult and time consuming.

    How can we utilize properly the instruments of Opentelemtry to make our code sound beautiful?

    During this presentation we will explain:
    - The various components of OpenTelemetry
    - The various core Objects required to instrument your code
    - Best practices related to instrumentation
    - The latest news related to OpenTelemetry

  handles:
    twitter: hrexed
    linkedin: hrexed
  session_url: https://vi.to/hubs/o11yfest/videos/5039

- id: prathima-janakiram
  name: Prathima Janakiram
  bio: |
    I am a technologist working in Silicon Valley for more than two decades. I have held a wide variety of roles from developer to application owner to operations at various datacom and telecom companies in the Bay Area. I started with monolithic application development managing networking devices more than two decades back and have seen the transformation of this landscape over the years to cloud native and SAAS offerings. Over the years, I have experimented with several programming languages and several networking technologies. I have now found my home as a developer advocate in Cisco Systems where I experiment with cloud automation technologies to ease the pain points of several personas, particularly the application developers.
  role: presenter
  title: "Self Service FSO deployments with Workflows"
  abstract: |
    Within an enterprise, some teams may be advanced in their path to cloud native app development and deployment while some may be challenged with legacy app transformations. Orchestration workflows provide the abstractions as app teams individually innovate and incorporate FSO tools of their choice.

    So, what has workflows got to do with this? It's about removing I&O teams from critical paths. It's about empowering app developers to be in control of their app deployments, app security and app performance. Considering that not all application teams within an enterprise innovate at the same pace, each team is bound to have varying requirements on the infrastructure. I & O teams are best positioned to cater to these varying requirements by the adoption of tools that provide abstractions so app teams can self provision the infrastructure per their requirements. Workflows, in general, inherently provide an abstraction functionality that can hide the inner workings of a deployment. This talk is to highlight the importance of allowing app developers to self service their own deployments with I&O teams providing them with a catalog of well tested building blocks including blocks for FSO. It's like those Lego blocks - you put those small blocks together to create your own masterpiece!

- id: shai-almog
  name: Shai Almog
  bio: |
    Developer advocate for [Lightrun](https://www.lightrun.com), co-founder of [Codename One](https://www.codenameone.com/), Creator of [DDT](https://github.com/ddtj/ddtj), open source hacker, speaker, author, blogger, Java rockstar and more. ex-Sun/Oracle guy with 30 years of professional development experience. Shai built virtual machines, development tools, mobile phone environments, banking systems, startup/enterprise backends, user interfaces, development frameworks and much more.
  role: presenter
  title: "Debugging at Scale in Production - Deep into your Containers with kubectl debug, KoolKits and Continuous Observability"
  abstract: |
    Brian Kernigham said: “Debugging is twice as hard as writing the code in the first place.”

    In fact, debugging in a modern production environment is even harder - orchestrators spinning containers up and down and weird networking wizardry that keeps everything glued together, make understanding systems that much more difficult than it used to be.

    And, while k8s is well understood by DevOps people by now, it remains a nut that developers are still trying to crack. Where do you start when there’s a production problem? How do you get the tools you’re used to in the remote container? How do you understand what is running where and what is its current state?

    In this talk, we will review debugging a production application deployed to a Kubernetes cluster, and review kubectl debug - a new feature from the Kubernetes sig-cli team. In addition, we’ll review the open source KoolKits project that offers a set of (opinionated) tools for kubectl debug.

    KoolKits builds on top of kubectl debug by adding everything you need right into the image. When logging into a container, we’re often hit with the scarcity of tools at our disposal. No vim (for better or worse), no DB clients, no htop, no debuggers, etc… KoolKits adds all the tools you need right out of the box and lets you inspect a production container easily without resorting to endless installation and configuration cycles for each needed package.

    We’ll finish the talk by delving into how to get better at debugging on a real-world scale. Specifically, we’ll talk about how to be disciplined in our continuous observability efforts by using tools that are built for k8s scale and can run well in those environments, while remaining ergonomic for day to day use.

    This session will go back and forth between explanation slides and demonstration of the topic at hand.
  handles:
    twitter: debugagent
    linkedin: shai-almog-81a42
  session_url: https://vi.to/hubs/o11yfest/videos/5009

- id: adrian-gonzalez
  name: Adrian Gonzalez
  bio: |
    I am a passionate and driven Principal Software Engineering Lead in the Commercial Software Engineering (CSE) organization at Microsoft. CSE is a global engineering team that works directly with the largest companies and not-for-profits in the world to tackle their most significant technical challenges. In my current role, my main responsibility is the management and development of 5- person engineering team. I identify projects and challenges for my team that mirror their interests and skillsets. Though we have diverse expertise, as a team we are all passionate about empowering customers to solve their problems and engaging in new problem areas to learn and grow.
  role: presenter
  title: "Seeing Your Product Succeed through User Telemetry"
  abstract: |
    The business value of observability for many enterprise customers comes in the form of user telemetry. Every business wants to know, 'Who are my users, when are they using, why, how, and what buttons are they touching?". This understanding can determine or define the success of your product.
  handles:
    linkedin: adrian-g-gonzalez
  session_url: https://vi.to/hubs/o11yfest/videos/5107

- id: zoe-steinkamp
  name: Zoe Steinkamp
  bio: |
    Zoe Steinkamp is a Developer Advocate for InfluxData. She has worked for InfluxData as a front end software engineer for over two years. Before InfluxData, she worked as a front end engineer for over 5 years in the original AngularJS. She originally went to a bootcamp for training in Python. Her favorite activities outside of work include traveling and gardening.
  role: presenter
  title: "Cleaning and Interpreting Time-series Metrics with InfluxDB"
  abstract: |
    Metric data can benefit from being standardized and condensed before being stored in your database. It can also be useful to be able to search and filter the data outside of your database. The flux data processing language is built for handling these tasks in the Flux VS code tool.

    Raw time series metrics data can benefit from clean-up and normalization before exposing it for broader use and storage. When dealing with large amounts of time series metrics, it can be helpful to be able to standardize the ways in which others can search through that data for specific time frames using easy to understand tags. This talk focuses on using Flux, InfluxDB’s data processing language, for addressing these challenges. Examples of how to leverage Flux to accomplish data cleansing and analytics through the browser and via Visual Studio will be demonstrated.
  handles:
    linkedin: zoe-steinkamp

- id: daniel-selans
  name: Daniel Selans
  bio: |
    Dan is a co-founder of Batch.sh, a data stream observability company. Dan previously worked at InVisionApp, New Relic and before that, spent some time doing integration work at data centers. He has been writing Go for 6+ years, works primarily in backend, listens to a lot of black metal and prefers Stella's over IPA's. He resides in Portland, Oregon but is originally from [Latvia](https://goo.gl/maps/9wruLSg4RBU2).
  role: presenter
  title: "Observability in Event Driven *"
  abstract: |
    Event driven systems are on the rise but there is still a significant lack of information about how to observe these complex systems.

    Event driven is not new - there are several well-known articles written about it but it remains difficult to find up-to date information on the various paradigms - architecture, implementation, component breakdowns or just some guidance on how to approach observability.

    In this talk, I will introduce the listener to event driven concepts and share observability patterns that have worked for our team.

    This information comes from first-hand experience designing, implementing and operating an event-driven system that our company uses to process over ten billion (protobuf) events per day.

    Learn how to set yourself up for success when working with async-heavy systems.

    (Rough) Outline of the talk:

    1. Introduction to event driven concepts

    2. What is event driven? (<5 minutes)

    3. Component breakdown (<5 minutes)

    4. Observing Async

    5. Why is it hard? (<=5 minutes)

    6. Patterns that work (10 minutes)

    7. What to avoid (5 minutes)

  handles:
    twitter: skey
    linkedin: dselans
  session_url: https://vi.to/hubs/o11yfest/videos/5043

- id: stephen-townshend
  name: Stephen Townshend
  bio: |
    Stephen pretended to be a performance engineer for thirteen years, and very recently started pretending to be an SRE. He is actually an actor, playing the role of a site reliability engineer. At some point along the way he lost touch with reality and is no longer sure if he is acting, or this has become reality. In the words of Robert Downey, Jr. in the film Tropic Thunder: “I know who I am. I’m a dude playing a dude disguised as another dude.”
  role: presenter
  title: "Bad Observability"
  abstract: |
    What are some antipatterns can hurt the success of our observability? What does “bad” observability look like?

    From my experience, most organizations have a lot of monitoring. And most of the time that monitoring isn’t able to answer basic questions about customer behaviour and experience, and isn’t being used as part of a feedback loop to pivot and make better business decisions.

    In this session I will explore both technical and cultural antipatterns that hinder observability. For example: - Lots of data but no insights - Monitoring a lot of technical metrics but not tracking customer behaviour and the impact of changes - Not knowing what the desired level of service is for the customer, or tracking it, or responding to it as part of a feedback loop - Misunderstanding what aggregates (averages, percentiles, etc.) mean and do not mean, or the impact of sampling intervals - Misunderstanding what certain metrics mean (for example, available memory on CPU’s, % CPU usage on containers and VM’s) - Siloed teams who do not share their monitoring with others …and many more.

    In this session my goal is to bring us back to outcomes. Rather than “do monitoring” for the sake of it, let’s be thoughtful about what we choose to measure and how we deal with the data that comes back, so that it drives better customer and business outcomes.

  handles:
    twitter: the_kiwi_sre
    linkedin: stephentownshend
  session_url: https://vi.to/hubs/o11yfest/videos/5008

- id: andreas-grabner
  name: Andreas Grabner
  bio: |
    Andreas Grabner has 20+ years of experience as a software developer, tester and architect and is an advocate for high-performing cloud scale applications. He is a contributor and DevRel for the CNCF open source project keptn (www.keptn.sh). Andreas is also a regular contributor to the DevOps community, a frequent speaker at technology conferences and regularly publishes articles on blog.dynatrace.com or medium. In his spare time you can most likely find him on one of the salsa dancefloors of the world (will resume once Covid is behind us)!
  role: presenter
  title: "Keptn: Putting Observability in the driving seat for DevOps & SRE automation"
  abstract: |
    Observability is the foundation giving us insights on how our systems currently behave. Keptn - a CNCF project - uses o11y to automate decisions in your delivery and ops automation.

    Its simple: You define SLOs! Keptn takes care of orchestrating your tools to deploy, test or release based on o11y!

    DevOps Platform Engineers and SREs are spending a lot of time integrating observability into their delivery and operations automation to automate decisions. This is done through lots of custom scripting, e.g: pull data from Jenkins, GitLab or Argo pipelines to make automated decisions based on the data coming out of Prometheus, OpenTelemetry ...

    Keptn standardizes how to pull data from your observability platform, how to analyze it by applying the concept of SLOs (Service Level Objectives) and how to integrate with your delivery, test, notification and configuration management tools.

    Keptn adopters have seen up to 90% reduction in custom coding to make observability a core component of their automation.

    In this session you learn how Keptn works, how the community is adopting it, how to integrate your own observability framework, how you can get started in minutes and how you can contribute to this open-source project.
  handles:
    twitter: grabnerandi
    linkedin: grabnerandi
  session_url: https://vi.to/hubs/o11yfest/videos/5007

- id: narmatha-bala
  name: Narmatha Bala
  bio: |
    Narmatha Bala is a Senior Software Engineering Manager in the Commercial Software Engineering (CSE) team and runs the Observability (chapter?) of the CSE Engineering Playbook, a best practices guide put together by development teams to accelerate the sharing of how best to work together, to quickly transfer learnings across teams with customers, particularly with new technologies and projects as a way to enable customers to carry the work forward and continue the development. CSE is a global engineering organization that works directly with the largest companies and not-for-profits in the world to tackle their most significant technical challenges.
  role: presenter
  title: "Confidence in Chaos; Observability in Testing"
  abstract: |
    There is a difference between applying traditional observability practices and how they are applied for each custom project and scenario.

    Everyone wants to use observability because it can reduce time between a problem and a solution, but there is a difference between applying traditional observability practices and how they are applied for each custom project and scenario. Narmatha Bala is a Senior Software Engineering Manager in the Commercial Software Engineering (CSE) team and runs the Observability chapter of the CSE Engineering Playbook, a best practices guide put together by development teams to accelerate the sharing of how best to work together, to quickly transfer learnings across teams with customers, particularly with new technologies and projects as a way to enable customers to carry the work forward and continue the development. CSE is a global engineering organization that works directly with the largest companies and not-for-profits in the world to tackle their most significant technical challenges.

    In this talk, Narmatha will share her experiences in instilling Observability best practices with engineers who use best utilize observability in applications versus engineers that think they do. She will cover why actionable failures are a good thing in system design, how to best define Service Level Agreements and Objectives (SLAs, SLOs), and where monitoring fits into the process. This talk is best suited for intermediate practitioners who want to improve their testing by improving their observability practices.
  handles:
    twitter: narmathabala
    linkedin: narmathabala
  session_url: https://vi.to/hubs/o11yfest/videos/5038
  preactions:
  - contributor: Stephen Townshend
    youtube_id: sVmJWnRgWHQ
    start_time: 310
    video_url: https://youtu.be/sVmJWnRgWHQ?t=310

- id: martin-mao
  name: Martin Mao
  bio: |
    Martin Mao is the co-founder and CEO of Chronosphere. He was previously at Uber, where he led the development and SRE teams that created and operated M3. Prior to that, he was a technical lead on the EC2 team at AWS and has also worked for Microsoft and Google. He and his family are based in our Seattle hub and he enjoys playing soccer and eating meat pies in his spare time.
  role: presenter
  title: "Is MTTR still relevant in a modern, cloud native world?"
  abstract: |
    MTTR has long been an essential failure metric. However, in a cloud native world, P95 and P99 have become more meaningful measurements. And time to remediation -not repair- is most important. During the talk, Martin will share an alternative to MTTR and how it can become your new P99 of remediation.

    Mean time to repair (MTTR) has long been an essential failure metric measuring the average time it takes to repair or restore a system to functionality. But why, in the age of microservices and containers, are we still using a metric with its origins in measuring equipment failures within factories? Mean, or average, is no longer a relevant metric for most organizations, with P95 and P99 becoming the more meaningful measurement. Repair, or sometimes restore, is also problematic. In most cases the most important time period to measure is the time to remediation, or the time to alleviate customer pain, restoring the service to acceptable levels of availability and performance. In this session, Martin will introduce an alternative to MTTR, and share real-life examples and lessons learned to explain how this new way of thinking can become your new P99 of remediation time.

  handles:
    twitter: martin_c_mao
    linkedin: martinmao
  session_url: https://vi.to/hubs/o11yfest/videos/5087
  preactions:
  - contributor: Stephen Townshend
    youtube_id: sVmJWnRgWHQ
    start_time: 669
    video_url: https://youtu.be/sVmJWnRgWHQ?t=669

- id: piyush-verma
  name: Piyush Verma
  bio: |
    Piyush Verma is co-founder and CTO at Last9.io, an SRE platform that aims to minimize the toil that SREs and decision-makers need to go through to reduce the time to make a decision. Earlier, he led SRE @ TrustingSocial.com to produce 600 million credit scores a day across 4 countries. In his past life, he built oogway.in (exit to TrustingSocial.com), datascale.io (exit to Datastax), and siminars.com.
  role: presenter
  title: "Building OpenMetrics Exporter"
  abstract: |
    Openmetrics-exporter (OME) is an Observability-as-Code software that metrics what Terraform is to Cloud Operations. OME uses HCL configs written in HCL syntax to connect to cloud-native sources and collate metrics using simple pipes, absorbing all challenges of distributed systems underneath.

    Openmetrics-exporter, or OME, is an Observability-as-Code framework that reduces the toil of finding-and-combining useful metrics from layers and hundreds of components involved in modern cloud-native systems. Every source, component, or metric is just a simple configuration file because the only "code" you should focus on is for your customers.

    It leverages plugin architecture to support data sources. It relies heavily on data frame processing to combine metrics from various metrics sources before they are all converted into Openmetrics format, ready to be piped out by a Prometheus. Traditionally, such correlation and post-processing have been a responsibility of additional Data Pipelines but with OME it's as simple as writing a configuration file. At the core of it, OME uses Hashicorp Configuration Language (HCL) to build a DSL that can allow declarative input to build metric Pipelines.

    The talk is largely about what can you solve using OME. But it also takes a very short journey of ""behind-the-scenes""

    The need to build Openmetrics-exporter, picking a configuration language that was easily editable by humans, building a DSL around it, and more importantly leveraging Golang for Data Science needs.
  handles:
    twitter: realmeson10
    linkedin: meson10
  session_url: https://vi.to/hubs/o11yfest/videos/5042

- id: alex-boten
  name: Alex Boten
  bio: |
    Alex Boten is a Senior Staff Software Engineer at Lightstep and has spent the last ten years helping organizations adapt to a cloud-native landscape. From building core network infrastructure to mobile client applications and everything in between, Alex has first-hand knowledge of how complex troubleshooting distributed applications is.

    This led him to the domain of observability and contributing to open-source projects in the space. A contributor, approver, and maintainer in several aspects of OpenTelemetry, Alex has helped evolve the project from its early days in 2019 into the massive community effort that it is today.

    More than anything, Alex loves making sense of the technology around us and sharing his learnings with others.
  role: presenter
  title: "How the OpenTelemetry Collector puts you in the driver seat"
  abstract: |
    After spending hours, days, weeks of effort ensuring applications are producing good telemetry, the last thing anyone wants is to touch that code ever again. As needs change, you want the flexibility to try new solutions. What if there was an easy way to do this? Enters the OpenTelemetry Collector.

    Instrumenting code is a pain. OpenTelemetry provides the tooling necessary to instrument code once and for all. Gone are the days of vendor lock-in, everyone can now use an open standard. The OpenTelemetry Collector provides even more control over your data, allowing you to send data to any number of telemetry backends without ever touching application code.

    In this talk, you‚'ll learn:

    * What the OpenTelemetry Collector is

    * How it provides maximum control & flexibility for your data

    * The ways you can extend the Collector

    It's your data! Retain control of it with the Collector.
  handles:
    twitter: codeboten
    linkedin: codeboten
  session_url: https://vi.to/hubs/o11yfest/videos/5031

- id: reese-lee
  name: Reese Lee
  bio: |
    I'm Reese, and I love solving puzzles! That's really what has ultimately led me here, working with OpenTelemetry users and enabling my teams on OpenTelemetry. Helping customers get their data into our backend platform, how to increase awareness of this actively evolving tooling, how to improve our user experience - these are all puzzles that are of vast interest to me.

    Before moving to the OpenTelemetry Community Team at New Relic as a Developer Relations Engineer, I was a Technical Support Engineer, where I provided support to our APM users (specifically with our .NET, Python, PHP, and Go agents). Although my role now is no longer primarily focused on helping our customers troubleshoot issues (the vast majority of which was missing data of some sort), it's something I still enjoy doing greatly. There's always something new to learn, some new root cause we haven't encountered before.

    I partake in other fun activities, too! Such as, but not limited to: paddleboarding, eating, and traveling.
  role: presenter
  title: "Where The Heck Are My Spans??"
  abstract: |
    The whole point of observability is being able to see and analyze your data. So what do you do when your traces are fragmented, or when you are not seeing any spans at all?

    There are few things more frustrating in observability than missing data - isn't being able to see your data the whole point of observability? You've checked and re-checked your configuration, and everything looks correct. You look at the console for any messages, but it's empty -- nothing helpful there. So... What now? How do you go about figuring what's happening?

    In this lightning session, I'll be talking specifically about trace data. I'll cover how to enable logging in your SDK, some error codes and what they might indicate, and general limits your backend vendor may be imposing that could be impacting your spans.
  handles:
    linkedin: reese-lee
  session_url: https://vi.to/hubs/o11yfest/videos/5088
  preactions:
  - contributor: Stephen Townshend
    youtube_id: sVmJWnRgWHQ
    start_time: 106
    video_url: https://youtu.be/sVmJWnRgWHQ?t=106


- id: vineeth-pothulapati
  name: Vineeth Pothulapati
  bio: |
    Vineeth is a cloud, distributed systems enthusiast and maintainer to OpenTelemetry Operator, a contributor to Kubernetes, Cortex, and Open Policy Agent. He worked as a shadow for previous Kubernetes releases and was also a docs lead for Kubernetes 1.18 release. He is currently working on Promscale & Tobs as a Product Manager with Timescale. Previously, he was a CNCF mentee with Cortex and Open Policy Agent and a Google Summer of Code intern with The Postgres Operator. Vineeth co-founded and organizes CNCF Hyderabad meet-ups and also gave several talks on CNCF technologies.
  role: presenter
  title: "Easing OpenTelemetry adoption using the OpenTelemetry operator"
  abstract: |
    OpenTelemetry has emerged as the new standard for instrumentation and collection of observability signals. OpenTelemetry adoption isn‚Äôt straightforward and there is no easy way to get started because adoption is a complex process involving many moving pieces.

    This process involves understanding the business applications and their instrumentation layer, deploying the OpenTelemetry agent and collector followed by configuring the receivers, processors, exporters, and extensions in the OpenTelemetry collector. This talk will help you understand all the pieces involved in deploying the complete OpenTelemetry stack and how they fit together.

    This talk covers:

    1. Explaining the Opentelemetry collector deployment modes.
    2. Explaining the instrumentation layer.
    3. Auto-instrumentation offered by the operator.
    4. Explaining the OpenTelemetry collector configuration options and how to define data flow pipelines.
    5. Auto-upgrades using the Otel-operator.

    The OpenTelemetry operator offers a seamless experience to the users of the OpenTelemetry collector in managing and upgrading the collectors across multiple versions with breaking changes. In this talk, Vineeth will cover how to get started with OpenTelemetry using the Opentelemetry Operator by explaining all the features offered to make your deployments and day two operations much more reliable.

    The OpenTelemetry Operator is gaining adoption with recent advancements in the operator. This talk helps users get started with the OpenTelemetry stack. We‚Äôll cover how to deploy the OpenTelemetry collector, leveraging auto-instrumentation offered in Java, Nodejs, and Python applications. Today the OpenTelemetry slack channels have multiple questions where users are having issues in getting started. They have trouble finding the recommended way to deploy and operate collectors. This talk will help users as a getting started guide for OpenTelemetry deployment as well as serve as an introduction today to operations such as scaling and handling breaking changes in the OpenTelemetry configuration during the upgrades. Ultimately, this is an educational contribution that will help the community in getting started and managing the OpenTelemetry stack."
  handles:
    twitter: vineeetth
    linkedin: vineeth-pothulapati

- id: ramon-guiu
  name: Ramon Guiu
  bio: |
    Ramon is VP of Observability products at Timescale where he is building Promscale, a unified observability backend for metrics, traces and logs on top of TimescaleDB and PostgreSQL.

    Before Timescale, Ramon was VP of Product Management at New Relic where he initially led their infrastructure monitoring product and later their transition to open instrumentation standards including Prometheus, OpenMetrics and OpenTelemetry.
  role: presenter
  title: "Going deep into the (mis)behaviors of your distributed systems with OpenTelemetry and SQL"
  abstract: |
    Traces hold a treasure of information about how all the different components in your systems behave and interact. Yet, open source tools for analyzing trace data typically focus on investigating individual traces and SaaS tools allow you to query traces for basic data aggregation or pre-defined analysis and correlations. But the hardest problems require the ability to slice and dice, aggregate, join and analyze the data in very specific ways that are usually not available in these tools.

    In this talk, we will show how you can query OpenTelemetry traces with good old SQL to identify unexpected behaviours in your microservices and narrow down on where bottlenecks are occurring to answer questions like:

    "For service X with elevated load, show me which upstream service is causing the load," or "Show me the cost of requests A, B, and C in terms of backend work in this service"

    To perform this analysis, we will use free tools. We will send OpenTelemetry traces to a TimescaleDB/PostgreSQL database via Promscale and we will use Grafana to visualize the results of SQL queries against that database.
  handles:
    twitter: ramonguiu
    linkedin: ramonguiu
  session_url: https://vi.to/hubs/o11yfest/videos/5085
